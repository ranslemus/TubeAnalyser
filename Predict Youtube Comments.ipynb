{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q pandas torch transformers accelerate scikit-learn joblib tqdm"],"metadata":{"id":"z1rLEdkD69-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749215529281,"user_tz":-420,"elapsed":139713,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"5b1f1efc-9bbb-4649-ce38-508ff2e1b69c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQjmcuLdRx4v","executionInfo":{"status":"ok","timestamp":1749215593595,"user_tz":-420,"elapsed":19535,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"209479f2-6ace-476e-a1ce-43487d4381a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import BertTokenizer, BertModel, RobertaTokenizerFast, RobertaForSequenceClassification\n","from tqdm import tqdm\n","import warnings\n","import joblib\n","import os"],"metadata":{"id":"Vbanz6_S_B6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_comment = '''Omg you played Psych!! I wrote the soundtrack for that game, I said to the developers that if there was one streamer I wanted to play Psych it would be Teo, how frigging cool!! Edit: At least you played some of it..ðŸ˜‚'''"],"metadata":{"id":"8Ofn-Ga3DG48"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvzZcMbNnuVa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749217822185,"user_tz":-420,"elapsed":1671,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"ac513041-6dff-4af5-cef2-50b3e9900f9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Google Drive mounted. Looking for models in: /content/drive/MyDrive/ML_Models\n"]}],"source":["GOOGLE_DRIVE_BASE_PATH = '/content/drive/MyDrive/ML_Models'\n","SENTIMENT_MODEL_PATH = os.path.join(GOOGLE_DRIVE_BASE_PATH, 'saved_model_sentiment')\n","EMOTION_MODEL_PATH = os.path.join(GOOGLE_DRIVE_BASE_PATH, 'saved_model_emotion')\n","CUSTOM_BERT_MODEL_PATH = '/content/drive/MyDrive/ML_Models/XGBOOST _Model/bert_model'\n","CUSTOM_BERT_TOKENIZER_PATH = '/content/drive/MyDrive/ML_Models/XGBOOST _Model/bert_tokenizer'\n","LIKE_COUNT_MODEL_PATH = '/content/drive/MyDrive/ML_Models/XGBOOST _Model/xgboost_BERT_embeddings.pkl'\n","\n","SENTIMENT_LABELS = ['positive', 'negative', 'neutral']\n","EMOTION_LABELS = [\"joy\", \"sadness\", \"anger\", \"fear\", \"disgust\", \"surprise\", \"neutral\"]\n","\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(f\"Google Drive mounted. Looking for models in: {GOOGLE_DRIVE_BASE_PATH}\")\n","except ImportError:\n","    print(\"Google Colab 'drive' module not found. Assuming not in Colab or Drive already mounted.\")\n","except Exception as e:\n","    print(f\"An error occurred during Google Drive mounting: {e}\")"]},{"cell_type":"code","source":["print(f\"--- Loading custom BERT from '{CUSTOM_BERT_MODEL_PATH}' ---\")\n","try:\n","    # Load your fine-tuned tokenizer and model from the specified paths\n","    embedding_tokenizer = BertTokenizer.from_pretrained(CUSTOM_BERT_TOKENIZER_PATH)\n","    embedding_model = BertModel.from_pretrained(CUSTOM_BERT_MODEL_PATH)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    embedding_model.to(device)\n","    print(f\"âœ… Custom BERT model and tokenizer loaded successfully on device: {device}\")\n","except Exception as e:\n","    print(f\"âŒ Error loading custom BERT model/tokenizer: {e}\")\n","    embedding_model = None\n","\n","# --- Function to Generate Embeddings (No changes needed) ---\n","def get_single_bert_embedding(text):\n","    \"\"\"Generates a BERT embedding for a single text string.\"\"\"\n","    if embedding_model is None:\n","        return None\n","    embedding_model.eval()\n","    inputs = embedding_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","    with torch.no_grad():\n","        outputs = embedding_model(**inputs)\n","    # Use the [CLS] token's embedding as the sentence representation\n","    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","    return cls_embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1LaPXyO-vG_","executionInfo":{"status":"ok","timestamp":1749217822465,"user_tz":-420,"elapsed":283,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"2064aff1-90a4-4d24-beda-7b670bc00249"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Loading custom BERT from '/content/drive/MyDrive/ML_Models/XGBOOST _Model/bert_model' ---\n","âœ… Custom BERT model and tokenizer loaded successfully on device: cpu\n"]}]},{"cell_type":"code","source":["def predict_on_text(text, model, tokenizer):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad(): #\n","        logits = model(**inputs).logits\n","\n","    predicted_class_id = torch.argmax(logits, dim=-1).item()\n","\n","    predicted_label = model.config.id2label[predicted_class_id]\n","\n","    return predicted_label, predicted_class_id"],"metadata":{"id":"Y6gSZJaXBFBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"--- Loading Models and Tokenizers ---\")\n","\n","try:\n","    print(f\"Loading sentiment model from: {SENTIMENT_MODEL_PATH}\")\n","    sentiment_tokenizer = RobertaTokenizerFast.from_pretrained(SENTIMENT_MODEL_PATH)\n","    sentiment_model = RobertaForSequenceClassification.from_pretrained(SENTIMENT_MODEL_PATH)\n","    print(\"Sentiment model and tokenizer loaded successfully.\")\n","\n","    print(f\"\\nLoading emotion model from: {EMOTION_MODEL_PATH}\")\n","    emotion_tokenizer = RobertaTokenizerFast.from_pretrained(EMOTION_MODEL_PATH)\n","    emotion_model = RobertaForSequenceClassification.from_pretrained(EMOTION_MODEL_PATH)\n","    print(\"Emotion model and tokenizer loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading models or tokenizers: {e}\")\n","    print(\"Ensure the paths are correct and the model files are intact.\")\n","    exit()\n","try:\n","    predicted_sentiment, _ = predict_on_text(sample_comment, sentiment_model, sentiment_tokenizer)\n","except Exception as e:\n","    print(f\"  Error predicting sentiment: {e}\")\n","\n","# Predict Emotion\n","try:\n","    predicted_emotion, _ = predict_on_text(sample_comment, emotion_model, emotion_tokenizer)\n","except Exception as e:\n","    print(f\"  Error predicting emotion: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrUfngM97UMp","executionInfo":{"status":"ok","timestamp":1749217825007,"user_tz":-420,"elapsed":2530,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"9f795456-7039-46c7-fa87-3c016c3addda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Loading Models and Tokenizers ---\n","Loading sentiment model from: /content/drive/MyDrive/ML_Models/saved_model_sentiment\n","Sentiment model and tokenizer loaded successfully.\n","\n","Loading emotion model from: /content/drive/MyDrive/ML_Models/saved_model_emotion\n","Emotion model and tokenizer loaded successfully.\n"]}]},{"cell_type":"code","source":["def load_XGB_model(model_path):\n","    \"\"\"Loads a saved XGBoost model from a .pkl file.\"\"\"\n","    if not os.path.exists(model_path):\n","        print(f\"âŒ Error: Model file not found at {model_path}\")\n","        return None\n","    try:\n","        model = joblib.load(model_path)\n","        print(f\"âœ… XGBoost model loaded successfully from {model_path}\")\n","        return model\n","    except Exception as e:\n","        print(f\"âŒ Error loading XGBoost model: {e}\")\n","        return None\n","\n","like_count_model = load_XGB_model(LIKE_COUNT_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8SLx9vP-VTo","executionInfo":{"status":"ok","timestamp":1749217825051,"user_tz":-420,"elapsed":35,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"4526b623-4f79-4fd5-e07e-0932903c7350"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… XGBoost model loaded successfully from /content/drive/MyDrive/ML_Models/XGBOOST _Model/xgboost_BERT_embeddings.pkl\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:24] WARNING: /workspace/src/gbm/gbtree.cc:363: \n","  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n","  machine. Consider using `save_model/load_model` instead. See:\n","\n","    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n","\n","  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:24] WARNING: /workspace/src/gbm/gbtree.cc:388: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:24] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:50:24] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"code","source":["text_input_for_embedding = f\"{sample_comment} [SEP] {predicted_emotion} [SEP] {predicted_sentiment}\"\n","print(f\"Step 3: Created combined input for embedding model.\")\n","print(f\"  > Combined Text: \\\"{text_input_for_embedding[:80]}...\\\"\")\n","\n","print(\"Step 4: Generating BERT embedding...\")\n","final_embedding = get_single_bert_embedding(text_input_for_embedding)\n","if final_embedding is not None:\n","  print(f\"  > Embedding generated with shape: {final_embedding.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14oSeWOg-33P","executionInfo":{"status":"ok","timestamp":1749217826291,"user_tz":-420,"elapsed":1232,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"5b9f4934-4ba5-484b-bed1-ccf472488020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 3: Created combined input for embedding model.\n","  > Combined Text: \"Omg you played Psych!! I wrote the soundtrack for that game, I said to the devel...\"\n","Step 4: Generating BERT embedding...\n","  > Embedding generated with shape: (1, 768)\n"]}]},{"cell_type":"code","source":["print(\"\\n--- Predicting on Your Sample Comment ---\")\n","print(f\"\\nSample Comment: \\\"{sample_comment}\\\"\")\n","print(f\"  --> Predicted Sentiment: {predicted_sentiment.upper()}\")\n","print(f\"  --> Predicted Emotion:   {predicted_emotion.capitalize()}\")\n","\n","if final_embedding is not None:\n","\n","        predicted_likes = like_count_model.predict(final_embedding)\n","        final_prediction = max(0, predicted_likes[0])\n","        print(f\"  --> Predicted Like Count: {round(final_prediction)}\")\n","else:\n","    print(\"\\nPrediction failed because one or more models could not be loaded.\")"],"metadata":{"id":"Egur2hXcAESY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749217826296,"user_tz":-420,"elapsed":4,"user":{"displayName":"Bryan Cristhoper Chandra Putra (Hiratax)","userId":"16185877708408979100"}},"outputId":"fadd1dee-b8d6-4795-b611-5e01c97deeb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Predicting on Your Sample Comment ---\n","\n","Sample Comment: \"Omg you played Psych!! I wrote the soundtrack for that game, I said to the developers that if there was one streamer I wanted to play Psych it would be Teo, how frigging cool!! Edit: At least you played some of it..ðŸ˜‚\"\n","  --> Predicted Sentiment: POSITIVE\n","  --> Predicted Emotion:   Surprise\n","  --> Predicted Like Count: 154\n"]}]}]}